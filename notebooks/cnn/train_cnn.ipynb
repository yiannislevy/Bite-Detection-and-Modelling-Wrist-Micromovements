{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-02-03T20:38:07.114197Z",
     "start_time": "2024-02-03T20:38:07.109217Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "from keras.optimizers.legacy import Adam as LegacyAdam\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "import pickle as pkl\n",
    "from src.utils.data_transform import *\n",
    "from src.utils.preprocessing import load_split_data\n",
    "import pandas as pd\n",
    "import os \n",
    "import pickle \n",
    "import json\n",
    "from src.utils.data_io import save_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [],
   "source": [
    "def load_data(test_subject, subject_to_indices):\n",
    "    training_data, testing_data = [], []\n",
    "    training_labels, testing_labels = [], []\n",
    "\n",
    "    # Load data by sessions based on subject_to_indices mapping\n",
    "    for subject, sessions in subject_to_indices.items():\n",
    "        subject_data, subject_labels = [], []\n",
    "        for session_id in sessions:\n",
    "            session_data, session_labels = load_session_data(f\"../data/ProcessedSubjects/MajorityLabel/sessions/grav_med_meanstd3/session_{session_id}.pkl\")\n",
    "            subject_data.append(session_data)\n",
    "            subject_labels.append(session_labels)\n",
    "        \n",
    "        # Aggregate data for each subject\n",
    "        subject_data = np.concatenate(subject_data, axis=0)\n",
    "        subject_labels = np.concatenate(subject_labels, axis=0)\n",
    "        \n",
    "        # Distribute data into training or testing based on subject ID\n",
    "        if str(subject) == str(test_subject):\n",
    "            testing_data.append(subject_data)\n",
    "            testing_labels.append(subject_labels)\n",
    "        else:\n",
    "            training_data.append(subject_data)\n",
    "            training_labels.append(subject_labels)\n",
    "\n",
    "    # Combine all training and testing data and labels\n",
    "    training_data = np.concatenate(training_data, axis=0)\n",
    "    training_labels = np.concatenate(training_labels, axis=0)\n",
    "    testing_data = np.concatenate(testing_data, axis=0)\n",
    "    testing_labels = np.concatenate(testing_labels, axis=0)\n",
    "\n",
    "    return training_data, training_labels, testing_data, testing_labels"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-03T20:38:07.619040Z",
     "start_time": "2024-02-03T20:38:07.614955Z"
    }
   },
   "id": "e6db3b735e7aab70"
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [],
   "source": [
    "def load_session_data(path):\n",
    "    data = pd.read_pickle(path)\n",
    "    signal_data = np.array([item[0] for item in data])\n",
    "    signal_data = signal_data[:, :, 1:]  # Exclude the timestamps column\n",
    "    label_data = np.array([item[1] for item in data])\n",
    "    return signal_data, label_data"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-03T20:38:08.707531Z",
     "start_time": "2024-02-03T20:38:08.701905Z"
    }
   },
   "id": "6bf9be48179ef32"
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [],
   "source": [
    "def build_model(input_shape):\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(filters=64, kernel_size=10, activation='relu', input_shape=input_shape, padding='same'))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(Conv1D(filters=128, kernel_size=10, activation='relu', padding='same'))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(5, activation='softmax'))  # Assuming 5 classes for the output layer\n",
    "    # optimizer = Adam(learning_rate=1e-3)\n",
    "    optimizer = LegacyAdam(learning_rate=1e-3)\n",
    "    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=[\"accuracy\"])\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-03T20:38:09.684502Z",
     "start_time": "2024-02-03T20:38:09.678194Z"
    }
   },
   "id": "bd23a6c2f6f0f64b"
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [],
   "source": [
    "with open(\"../data/dataset-info-json/subject_to_indices.json\", \"r\") as f:\n",
    "    subject_to_indices = json.load(f)\n",
    "\n",
    "subject_to_indices = {int(k): v for k, v in subject_to_indices.items()}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-03T20:38:10.420192Z",
     "start_time": "2024-02-03T20:38:10.412356Z"
    }
   },
   "id": "22ff591737b11994"
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training without 1\n",
      "Epoch 1/32\n",
      "882/882 [==============================] - 11s 12ms/step - loss: 0.7561 - accuracy: 0.7377\n",
      "Epoch 2/32\n",
      "882/882 [==============================] - 11s 12ms/step - loss: 0.6544 - accuracy: 0.7739\n",
      "Epoch 3/32\n",
      "882/882 [==============================] - 11s 12ms/step - loss: 0.6315 - accuracy: 0.7818\n",
      "Epoch 4/32\n",
      "882/882 [==============================] - 11s 12ms/step - loss: 0.6167 - accuracy: 0.7886\n",
      "Epoch 5/32\n",
      "882/882 [==============================] - 11s 12ms/step - loss: 0.6024 - accuracy: 0.7929\n",
      "Epoch 6/32\n",
      "882/882 [==============================] - 11s 12ms/step - loss: 0.5925 - accuracy: 0.7944\n",
      "Epoch 7/32\n",
      "882/882 [==============================] - 11s 12ms/step - loss: 0.5862 - accuracy: 0.7975\n",
      "Epoch 8/32\n",
      "882/882 [==============================] - 11s 12ms/step - loss: 0.5772 - accuracy: 0.8006\n",
      "Epoch 9/32\n",
      "882/882 [==============================] - 11s 13ms/step - loss: 0.5718 - accuracy: 0.8007\n",
      "Epoch 10/32\n",
      "882/882 [==============================] - 11s 12ms/step - loss: 0.5649 - accuracy: 0.8029\n",
      "Epoch 11/32\n",
      "882/882 [==============================] - 11s 13ms/step - loss: 0.5588 - accuracy: 0.8069\n",
      "Epoch 12/32\n",
      "882/882 [==============================] - 11s 13ms/step - loss: 0.5521 - accuracy: 0.8083\n",
      "Epoch 13/32\n",
      "882/882 [==============================] - 10s 12ms/step - loss: 0.5485 - accuracy: 0.8088\n",
      "Epoch 14/32\n",
      "882/882 [==============================] - 10s 12ms/step - loss: 0.5422 - accuracy: 0.8112\n",
      "Epoch 15/32\n",
      "882/882 [==============================] - 10s 11ms/step - loss: 0.5384 - accuracy: 0.8118\n",
      "Epoch 16/32\n",
      "882/882 [==============================] - 11s 12ms/step - loss: 0.5340 - accuracy: 0.8142\n",
      "Epoch 17/32\n",
      "882/882 [==============================] - 10s 11ms/step - loss: 0.5302 - accuracy: 0.8143\n",
      "Epoch 18/32\n",
      "882/882 [==============================] - 10s 11ms/step - loss: 0.5255 - accuracy: 0.8153\n",
      "Epoch 19/32\n",
      "882/882 [==============================] - 10s 11ms/step - loss: 0.5212 - accuracy: 0.8167\n",
      "Epoch 20/32\n",
      "882/882 [==============================] - 10s 11ms/step - loss: 0.5191 - accuracy: 0.8181\n",
      "Epoch 21/32\n",
      "882/882 [==============================] - 10s 11ms/step - loss: 0.5135 - accuracy: 0.8206\n",
      "Epoch 22/32\n",
      "882/882 [==============================] - 11s 12ms/step - loss: 0.5086 - accuracy: 0.8215\n",
      "Epoch 23/32\n",
      "882/882 [==============================] - 10s 12ms/step - loss: 0.5024 - accuracy: 0.8218\n",
      "Epoch 24/32\n",
      "882/882 [==============================] - 11s 12ms/step - loss: 0.5010 - accuracy: 0.8238\n",
      "Epoch 25/32\n",
      "882/882 [==============================] - 10s 12ms/step - loss: 0.4981 - accuracy: 0.8242\n",
      "Epoch 26/32\n",
      "882/882 [==============================] - 11s 12ms/step - loss: 0.4925 - accuracy: 0.8267\n",
      "Epoch 27/32\n",
      "882/882 [==============================] - 10s 11ms/step - loss: 0.4871 - accuracy: 0.8289\n",
      "Epoch 28/32\n",
      "882/882 [==============================] - 10s 12ms/step - loss: 0.4818 - accuracy: 0.8297\n",
      "Epoch 29/32\n",
      "882/882 [==============================] - 11s 12ms/step - loss: 0.4766 - accuracy: 0.8317\n",
      "Epoch 30/32\n",
      "882/882 [==============================] - 11s 12ms/step - loss: 0.4762 - accuracy: 0.8299\n",
      "Epoch 31/32\n",
      "882/882 [==============================] - 11s 12ms/step - loss: 0.4729 - accuracy: 0.8321\n",
      "Epoch 32/32\n",
      "882/882 [==============================] - 11s 12ms/step - loss: 0.4692 - accuracy: 0.8334\n",
      "262/262 [==============================] - 3s 10ms/step - loss: 0.6189 - accuracy: 0.7854\n",
      "Training without 2\n",
      "Epoch 1/32\n",
      "904/904 [==============================] - 11s 12ms/step - loss: 0.7638 - accuracy: 0.7358\n",
      "Epoch 2/32\n",
      "904/904 [==============================] - 11s 12ms/step - loss: 0.6690 - accuracy: 0.7653\n",
      "Epoch 3/32\n",
      "904/904 [==============================] - 11s 12ms/step - loss: 0.6436 - accuracy: 0.7759\n",
      "Epoch 4/32\n",
      "904/904 [==============================] - 11s 12ms/step - loss: 0.6267 - accuracy: 0.7807\n",
      "Epoch 5/32\n",
      "904/904 [==============================] - 11s 12ms/step - loss: 0.6126 - accuracy: 0.7875\n",
      "Epoch 6/32\n",
      "904/904 [==============================] - 11s 12ms/step - loss: 0.6026 - accuracy: 0.7895\n",
      "Epoch 7/32\n",
      "904/904 [==============================] - 11s 12ms/step - loss: 0.5937 - accuracy: 0.7924\n",
      "Epoch 8/32\n",
      "904/904 [==============================] - 11s 12ms/step - loss: 0.5850 - accuracy: 0.7944\n",
      "Epoch 9/32\n",
      "904/904 [==============================] - 11s 12ms/step - loss: 0.5797 - accuracy: 0.7969\n",
      "Epoch 10/32\n",
      "904/904 [==============================] - 12s 13ms/step - loss: 0.5722 - accuracy: 0.7989\n",
      "Epoch 11/32\n",
      "904/904 [==============================] - 12s 13ms/step - loss: 0.5676 - accuracy: 0.8012\n",
      "Epoch 12/32\n",
      "904/904 [==============================] - 11s 12ms/step - loss: 0.5609 - accuracy: 0.8011\n",
      "Epoch 13/32\n",
      "904/904 [==============================] - 11s 12ms/step - loss: 0.5564 - accuracy: 0.8036\n",
      "Epoch 14/32\n",
      "904/904 [==============================] - 11s 12ms/step - loss: 0.5535 - accuracy: 0.8036\n",
      "Epoch 15/32\n",
      "904/904 [==============================] - 11s 12ms/step - loss: 0.5475 - accuracy: 0.8071\n",
      "Epoch 16/32\n",
      "904/904 [==============================] - 10s 12ms/step - loss: 0.5452 - accuracy: 0.8072\n",
      "Epoch 17/32\n",
      "904/904 [==============================] - 11s 12ms/step - loss: 0.5376 - accuracy: 0.8098\n",
      "Epoch 18/32\n",
      "904/904 [==============================] - 11s 12ms/step - loss: 0.5333 - accuracy: 0.8113\n",
      "Epoch 19/32\n",
      "904/904 [==============================] - 11s 12ms/step - loss: 0.5307 - accuracy: 0.8121\n",
      "Epoch 20/32\n",
      "904/904 [==============================] - 12s 13ms/step - loss: 0.5280 - accuracy: 0.8112\n",
      "Epoch 21/32\n",
      "904/904 [==============================] - 12s 13ms/step - loss: 0.5215 - accuracy: 0.8142\n",
      "Epoch 22/32\n",
      "904/904 [==============================] - 11s 12ms/step - loss: 0.5198 - accuracy: 0.8150\n",
      "Epoch 23/32\n",
      "904/904 [==============================] - 10s 12ms/step - loss: 0.5145 - accuracy: 0.8176\n",
      "Epoch 24/32\n",
      "904/904 [==============================] - 11s 12ms/step - loss: 0.5127 - accuracy: 0.8190\n",
      "Epoch 25/32\n",
      "904/904 [==============================] - 11s 12ms/step - loss: 0.5075 - accuracy: 0.8183\n",
      "Epoch 26/32\n",
      "904/904 [==============================] - 10s 12ms/step - loss: 0.5031 - accuracy: 0.8189\n",
      "Epoch 27/32\n",
      "904/904 [==============================] - 10s 11ms/step - loss: 0.5013 - accuracy: 0.8194\n",
      "Epoch 28/32\n",
      "904/904 [==============================] - 10s 11ms/step - loss: 0.4955 - accuracy: 0.8218\n",
      "Epoch 29/32\n",
      "904/904 [==============================] - 11s 12ms/step - loss: 0.4937 - accuracy: 0.8223\n",
      "Epoch 30/32\n",
      "904/904 [==============================] - 11s 12ms/step - loss: 0.4905 - accuracy: 0.8241\n",
      "Epoch 31/32\n",
      "904/904 [==============================] - 11s 12ms/step - loss: 0.4867 - accuracy: 0.8254\n",
      "Epoch 32/32\n",
      "904/904 [==============================] - 12s 13ms/step - loss: 0.4818 - accuracy: 0.8260\n",
      "219/219 [==============================] - 2s 10ms/step - loss: 0.5698 - accuracy: 0.8138\n",
      "Training without 3\n",
      "Epoch 1/32\n",
      "844/844 [==============================] - 11s 12ms/step - loss: 0.7373 - accuracy: 0.7466\n",
      "Epoch 2/32\n",
      "844/844 [==============================] - 10s 12ms/step - loss: 0.6398 - accuracy: 0.7784\n",
      "Epoch 3/32\n",
      "844/844 [==============================] - 11s 13ms/step - loss: 0.6167 - accuracy: 0.7865\n",
      "Epoch 4/32\n",
      "844/844 [==============================] - 10s 12ms/step - loss: 0.6046 - accuracy: 0.7917\n",
      "Epoch 5/32\n",
      "844/844 [==============================] - 10s 12ms/step - loss: 0.5928 - accuracy: 0.7947\n",
      "Epoch 6/32\n",
      "844/844 [==============================] - 10s 12ms/step - loss: 0.5815 - accuracy: 0.7991\n",
      "Epoch 7/32\n",
      "844/844 [==============================] - 10s 12ms/step - loss: 0.5752 - accuracy: 0.8019\n",
      "Epoch 8/32\n",
      "844/844 [==============================] - 10s 12ms/step - loss: 0.5668 - accuracy: 0.8018\n",
      "Epoch 9/32\n",
      "844/844 [==============================] - 10s 12ms/step - loss: 0.5634 - accuracy: 0.8043\n",
      "Epoch 10/32\n",
      "844/844 [==============================] - 10s 12ms/step - loss: 0.5560 - accuracy: 0.8052\n",
      "Epoch 11/32\n",
      "844/844 [==============================] - 10s 12ms/step - loss: 0.5459 - accuracy: 0.8080\n",
      "Epoch 12/32\n",
      "844/844 [==============================] - 10s 12ms/step - loss: 0.5424 - accuracy: 0.8103\n",
      "Epoch 13/32\n",
      "844/844 [==============================] - 10s 12ms/step - loss: 0.5364 - accuracy: 0.8115\n",
      "Epoch 14/32\n",
      "844/844 [==============================] - 10s 12ms/step - loss: 0.5349 - accuracy: 0.8125\n",
      "Epoch 15/32\n",
      "844/844 [==============================] - 10s 12ms/step - loss: 0.5294 - accuracy: 0.8140\n",
      "Epoch 16/32\n",
      "844/844 [==============================] - 10s 12ms/step - loss: 0.5233 - accuracy: 0.8177\n",
      "Epoch 17/32\n",
      "844/844 [==============================] - 10s 12ms/step - loss: 0.5199 - accuracy: 0.8165\n",
      "Epoch 18/32\n",
      "844/844 [==============================] - 10s 12ms/step - loss: 0.5141 - accuracy: 0.8195\n",
      "Epoch 19/32\n",
      "844/844 [==============================] - 10s 12ms/step - loss: 0.5090 - accuracy: 0.8199\n",
      "Epoch 20/32\n",
      "844/844 [==============================] - 10s 12ms/step - loss: 0.5069 - accuracy: 0.8221\n",
      "Epoch 21/32\n",
      "844/844 [==============================] - 10s 12ms/step - loss: 0.5005 - accuracy: 0.8224\n",
      "Epoch 22/32\n",
      "844/844 [==============================] - 10s 12ms/step - loss: 0.4987 - accuracy: 0.8242\n",
      "Epoch 23/32\n",
      "844/844 [==============================] - 10s 12ms/step - loss: 0.4954 - accuracy: 0.8227\n",
      "Epoch 24/32\n",
      "844/844 [==============================] - 10s 12ms/step - loss: 0.4891 - accuracy: 0.8260\n",
      "Epoch 25/32\n",
      "844/844 [==============================] - 10s 12ms/step - loss: 0.4857 - accuracy: 0.8276\n",
      "Epoch 26/32\n",
      "844/844 [==============================] - 10s 12ms/step - loss: 0.4816 - accuracy: 0.8289\n",
      "Epoch 27/32\n",
      "844/844 [==============================] - 10s 12ms/step - loss: 0.4749 - accuracy: 0.8310\n",
      "Epoch 28/32\n",
      "844/844 [==============================] - 10s 12ms/step - loss: 0.4719 - accuracy: 0.8325\n",
      "Epoch 29/32\n",
      "844/844 [==============================] - 10s 12ms/step - loss: 0.4710 - accuracy: 0.8326\n",
      "Epoch 30/32\n",
      "844/844 [==============================] - 10s 12ms/step - loss: 0.4667 - accuracy: 0.8337\n",
      "Epoch 31/32\n",
      "844/844 [==============================] - 10s 12ms/step - loss: 0.4622 - accuracy: 0.8360\n",
      "Epoch 32/32\n",
      "844/844 [==============================] - 10s 12ms/step - loss: 0.4567 - accuracy: 0.8368\n",
      "340/340 [==============================] - 3s 10ms/step - loss: 0.7027 - accuracy: 0.7657\n",
      "Training without 4\n",
      "Epoch 1/32\n",
      "883/883 [==============================] - 11s 13ms/step - loss: 0.6939 - accuracy: 0.7552\n",
      "Epoch 2/32\n",
      "883/883 [==============================] - 11s 12ms/step - loss: 0.5890 - accuracy: 0.7918\n",
      "Epoch 3/32\n",
      "883/883 [==============================] - 11s 12ms/step - loss: 0.5646 - accuracy: 0.7996\n",
      "Epoch 4/32\n",
      "883/883 [==============================] - 11s 12ms/step - loss: 0.5483 - accuracy: 0.8072\n",
      "Epoch 5/32\n",
      "883/883 [==============================] - 11s 12ms/step - loss: 0.5381 - accuracy: 0.8100\n",
      "Epoch 6/32\n",
      "883/883 [==============================] - 11s 12ms/step - loss: 0.5296 - accuracy: 0.8119\n",
      "Epoch 7/32\n",
      "883/883 [==============================] - 11s 12ms/step - loss: 0.5188 - accuracy: 0.8153\n",
      "Epoch 8/32\n",
      "883/883 [==============================] - 11s 12ms/step - loss: 0.5116 - accuracy: 0.8175\n",
      "Epoch 9/32\n",
      "883/883 [==============================] - 11s 12ms/step - loss: 0.5037 - accuracy: 0.8206\n",
      "Epoch 10/32\n",
      "883/883 [==============================] - 11s 12ms/step - loss: 0.4977 - accuracy: 0.8218\n",
      "Epoch 11/32\n",
      "883/883 [==============================] - 11s 12ms/step - loss: 0.4931 - accuracy: 0.8237\n",
      "Epoch 12/32\n",
      "883/883 [==============================] - 11s 12ms/step - loss: 0.4869 - accuracy: 0.8253\n",
      "Epoch 13/32\n",
      "883/883 [==============================] - 11s 12ms/step - loss: 0.4833 - accuracy: 0.8272\n",
      "Epoch 14/32\n",
      "883/883 [==============================] - 11s 12ms/step - loss: 0.4760 - accuracy: 0.8292\n",
      "Epoch 15/32\n",
      "883/883 [==============================] - 11s 12ms/step - loss: 0.4721 - accuracy: 0.8302\n",
      "Epoch 16/32\n",
      "883/883 [==============================] - 11s 12ms/step - loss: 0.4673 - accuracy: 0.8314\n",
      "Epoch 17/32\n",
      "883/883 [==============================] - 11s 12ms/step - loss: 0.4627 - accuracy: 0.8339\n",
      "Epoch 18/32\n",
      "883/883 [==============================] - 11s 12ms/step - loss: 0.4574 - accuracy: 0.8340\n",
      "Epoch 19/32\n",
      "883/883 [==============================] - 11s 12ms/step - loss: 0.4573 - accuracy: 0.8346\n",
      "Epoch 20/32\n",
      "883/883 [==============================] - 11s 12ms/step - loss: 0.4523 - accuracy: 0.8353\n",
      "Epoch 21/32\n",
      "883/883 [==============================] - 11s 12ms/step - loss: 0.4471 - accuracy: 0.8379\n",
      "Epoch 22/32\n",
      "883/883 [==============================] - 11s 12ms/step - loss: 0.4439 - accuracy: 0.8398\n",
      "Epoch 23/32\n",
      "883/883 [==============================] - 11s 12ms/step - loss: 0.4399 - accuracy: 0.8398\n",
      "Epoch 24/32\n",
      "883/883 [==============================] - 11s 12ms/step - loss: 0.4342 - accuracy: 0.8431\n",
      "Epoch 25/32\n",
      "883/883 [==============================] - 11s 12ms/step - loss: 0.4307 - accuracy: 0.8417\n",
      "Epoch 26/32\n",
      "883/883 [==============================] - 11s 12ms/step - loss: 0.4269 - accuracy: 0.8449\n",
      "Epoch 27/32\n",
      "883/883 [==============================] - 11s 12ms/step - loss: 0.4233 - accuracy: 0.8447\n",
      "Epoch 28/32\n",
      "883/883 [==============================] - 11s 12ms/step - loss: 0.4216 - accuracy: 0.8457\n",
      "Epoch 29/32\n",
      "883/883 [==============================] - 11s 12ms/step - loss: 0.4167 - accuracy: 0.8468\n",
      "Epoch 30/32\n",
      "883/883 [==============================] - 11s 12ms/step - loss: 0.4159 - accuracy: 0.8483\n",
      "Epoch 31/32\n",
      "883/883 [==============================] - 11s 13ms/step - loss: 0.4107 - accuracy: 0.8493\n",
      "Epoch 32/32\n",
      "883/883 [==============================] - 11s 12ms/step - loss: 0.4090 - accuracy: 0.8513\n",
      "261/261 [==============================] - 3s 10ms/step - loss: 1.2641 - accuracy: 0.6743\n",
      "Training without 5\n",
      "Epoch 1/32\n",
      "927/927 [==============================] - 12s 13ms/step - loss: 0.7485 - accuracy: 0.7399\n",
      "Epoch 2/32\n",
      "927/927 [==============================] - 12s 13ms/step - loss: 0.6566 - accuracy: 0.7717\n",
      "Epoch 3/32\n",
      "927/927 [==============================] - 12s 12ms/step - loss: 0.6308 - accuracy: 0.7806\n",
      "Epoch 4/32\n",
      "927/927 [==============================] - 12s 13ms/step - loss: 0.6130 - accuracy: 0.7853\n",
      "Epoch 5/32\n",
      "927/927 [==============================] - 12s 13ms/step - loss: 0.6017 - accuracy: 0.7903\n",
      "Epoch 6/32\n",
      "927/927 [==============================] - 12s 13ms/step - loss: 0.5938 - accuracy: 0.7942\n",
      "Epoch 7/32\n",
      "927/927 [==============================] - 12s 13ms/step - loss: 0.5841 - accuracy: 0.7957\n",
      "Epoch 8/32\n",
      "927/927 [==============================] - 12s 13ms/step - loss: 0.5785 - accuracy: 0.7986\n",
      "Epoch 9/32\n",
      "927/927 [==============================] - 12s 13ms/step - loss: 0.5711 - accuracy: 0.8009\n",
      "Epoch 10/32\n",
      "927/927 [==============================] - 12s 13ms/step - loss: 0.5648 - accuracy: 0.8023\n",
      "Epoch 11/32\n",
      "927/927 [==============================] - 12s 13ms/step - loss: 0.5592 - accuracy: 0.8040\n",
      "Epoch 12/32\n",
      "927/927 [==============================] - 12s 13ms/step - loss: 0.5545 - accuracy: 0.8067\n",
      "Epoch 13/32\n",
      "927/927 [==============================] - 12s 13ms/step - loss: 0.5475 - accuracy: 0.8066\n",
      "Epoch 14/32\n",
      "927/927 [==============================] - 12s 13ms/step - loss: 0.5421 - accuracy: 0.8094\n",
      "Epoch 15/32\n",
      "927/927 [==============================] - 12s 13ms/step - loss: 0.5390 - accuracy: 0.8104\n",
      "Epoch 16/32\n",
      "927/927 [==============================] - 12s 13ms/step - loss: 0.5323 - accuracy: 0.8125\n",
      "Epoch 17/32\n",
      "927/927 [==============================] - 12s 13ms/step - loss: 0.5304 - accuracy: 0.8124\n",
      "Epoch 18/32\n",
      "927/927 [==============================] - 12s 13ms/step - loss: 0.5255 - accuracy: 0.8135\n",
      "Epoch 19/32\n",
      "927/927 [==============================] - 12s 13ms/step - loss: 0.5206 - accuracy: 0.8149\n",
      "Epoch 20/32\n",
      "927/927 [==============================] - 12s 13ms/step - loss: 0.5132 - accuracy: 0.8183\n",
      "Epoch 21/32\n",
      "927/927 [==============================] - 12s 13ms/step - loss: 0.5114 - accuracy: 0.8187\n",
      "Epoch 22/32\n",
      "927/927 [==============================] - 12s 13ms/step - loss: 0.5078 - accuracy: 0.8207\n",
      "Epoch 23/32\n",
      "927/927 [==============================] - 12s 13ms/step - loss: 0.5038 - accuracy: 0.8213\n",
      "Epoch 24/32\n",
      "927/927 [==============================] - 12s 13ms/step - loss: 0.5010 - accuracy: 0.8246\n",
      "Epoch 25/32\n",
      "927/927 [==============================] - 12s 13ms/step - loss: 0.4981 - accuracy: 0.8227\n",
      "Epoch 26/32\n",
      "927/927 [==============================] - 12s 13ms/step - loss: 0.4923 - accuracy: 0.8253\n",
      "Epoch 27/32\n",
      "927/927 [==============================] - 12s 13ms/step - loss: 0.4891 - accuracy: 0.8261\n",
      "Epoch 28/32\n",
      "927/927 [==============================] - 12s 13ms/step - loss: 0.4861 - accuracy: 0.8272\n",
      "Epoch 29/32\n",
      "927/927 [==============================] - 12s 13ms/step - loss: 0.4852 - accuracy: 0.8277\n",
      "Epoch 30/32\n",
      "927/927 [==============================] - 12s 13ms/step - loss: 0.4781 - accuracy: 0.8301\n",
      "Epoch 31/32\n",
      "927/927 [==============================] - 12s 13ms/step - loss: 0.4752 - accuracy: 0.8308\n",
      "Epoch 32/32\n",
      "927/927 [==============================] - 12s 13ms/step - loss: 0.4705 - accuracy: 0.8322\n",
      "174/174 [==============================] - 2s 10ms/step - loss: 0.6500 - accuracy: 0.7947\n",
      "Training without 6\n",
      "Epoch 1/32\n",
      "899/899 [==============================] - 12s 13ms/step - loss: 0.7531 - accuracy: 0.7382\n",
      "Epoch 2/32\n",
      "899/899 [==============================] - 11s 13ms/step - loss: 0.6569 - accuracy: 0.7713\n",
      "Epoch 3/32\n",
      "899/899 [==============================] - 11s 13ms/step - loss: 0.6313 - accuracy: 0.7811\n",
      "Epoch 4/32\n",
      "899/899 [==============================] - 11s 13ms/step - loss: 0.6166 - accuracy: 0.7865\n",
      "Epoch 5/32\n",
      "899/899 [==============================] - 11s 13ms/step - loss: 0.6043 - accuracy: 0.7903\n",
      "Epoch 6/32\n",
      "899/899 [==============================] - 11s 13ms/step - loss: 0.5940 - accuracy: 0.7933\n",
      "Epoch 7/32\n",
      "899/899 [==============================] - 11s 13ms/step - loss: 0.5869 - accuracy: 0.7952\n",
      "Epoch 8/32\n",
      "899/899 [==============================] - 11s 13ms/step - loss: 0.5793 - accuracy: 0.7972\n",
      "Epoch 9/32\n",
      "899/899 [==============================] - 11s 13ms/step - loss: 0.5737 - accuracy: 0.7992\n",
      "Epoch 10/32\n",
      "899/899 [==============================] - 11s 13ms/step - loss: 0.5651 - accuracy: 0.8022\n",
      "Epoch 11/32\n",
      "899/899 [==============================] - 11s 13ms/step - loss: 0.5622 - accuracy: 0.8039\n",
      "Epoch 12/32\n",
      "899/899 [==============================] - 11s 13ms/step - loss: 0.5556 - accuracy: 0.8046\n",
      "Epoch 13/32\n",
      "899/899 [==============================] - 11s 13ms/step - loss: 0.5515 - accuracy: 0.8063\n",
      "Epoch 14/32\n",
      "899/899 [==============================] - 12s 13ms/step - loss: 0.5465 - accuracy: 0.8071\n",
      "Epoch 15/32\n",
      "899/899 [==============================] - 11s 13ms/step - loss: 0.5413 - accuracy: 0.8088\n",
      "Epoch 16/32\n",
      "899/899 [==============================] - 12s 13ms/step - loss: 0.5366 - accuracy: 0.8095\n",
      "Epoch 17/32\n",
      "899/899 [==============================] - 12s 13ms/step - loss: 0.5331 - accuracy: 0.8118\n",
      "Epoch 18/32\n",
      "899/899 [==============================] - 11s 13ms/step - loss: 0.5307 - accuracy: 0.8113\n",
      "Epoch 19/32\n",
      "899/899 [==============================] - 12s 13ms/step - loss: 0.5242 - accuracy: 0.8145\n",
      "Epoch 20/32\n",
      "899/899 [==============================] - 11s 13ms/step - loss: 0.5216 - accuracy: 0.8152\n",
      "Epoch 21/32\n",
      "899/899 [==============================] - 11s 13ms/step - loss: 0.5153 - accuracy: 0.8170\n",
      "Epoch 22/32\n",
      "899/899 [==============================] - 12s 13ms/step - loss: 0.5126 - accuracy: 0.8191\n",
      "Epoch 23/32\n",
      "899/899 [==============================] - 11s 13ms/step - loss: 0.5081 - accuracy: 0.8192\n",
      "Epoch 24/32\n",
      "899/899 [==============================] - 11s 13ms/step - loss: 0.5048 - accuracy: 0.8200\n",
      "Epoch 25/32\n",
      "899/899 [==============================] - 12s 13ms/step - loss: 0.5031 - accuracy: 0.8223\n",
      "Epoch 26/32\n",
      "899/899 [==============================] - 12s 13ms/step - loss: 0.4980 - accuracy: 0.8226\n",
      "Epoch 27/32\n",
      "899/899 [==============================] - 12s 13ms/step - loss: 0.4924 - accuracy: 0.8240\n",
      "Epoch 28/32\n",
      "899/899 [==============================] - 12s 13ms/step - loss: 0.4910 - accuracy: 0.8242\n",
      "Epoch 29/32\n",
      "899/899 [==============================] - 12s 13ms/step - loss: 0.4899 - accuracy: 0.8250\n",
      "Epoch 30/32\n",
      "899/899 [==============================] - 12s 13ms/step - loss: 0.4851 - accuracy: 0.8264\n",
      "Epoch 31/32\n",
      "899/899 [==============================] - 12s 13ms/step - loss: 0.4813 - accuracy: 0.8282\n",
      "Epoch 32/32\n",
      "899/899 [==============================] - 12s 13ms/step - loss: 0.4797 - accuracy: 0.8285\n",
      "229/229 [==============================] - 2s 10ms/step - loss: 0.6243 - accuracy: 0.7890\n",
      "Training without 7\n",
      "Epoch 1/32\n",
      "973/973 [==============================] - 13s 13ms/step - loss: 0.7488 - accuracy: 0.7386\n",
      "Epoch 2/32\n",
      "973/973 [==============================] - 12s 13ms/step - loss: 0.6560 - accuracy: 0.7739\n",
      "Epoch 3/32\n",
      "973/973 [==============================] - 12s 13ms/step - loss: 0.6306 - accuracy: 0.7813\n",
      "Epoch 4/32\n",
      "973/973 [==============================] - 12s 13ms/step - loss: 0.6143 - accuracy: 0.7880\n",
      "Epoch 5/32\n",
      "973/973 [==============================] - 13s 13ms/step - loss: 0.6025 - accuracy: 0.7914\n",
      "Epoch 6/32\n",
      "973/973 [==============================] - 13s 13ms/step - loss: 0.5911 - accuracy: 0.7948\n",
      "Epoch 7/32\n",
      "973/973 [==============================] - 13s 13ms/step - loss: 0.5829 - accuracy: 0.7964\n",
      "Epoch 8/32\n",
      "973/973 [==============================] - 13s 13ms/step - loss: 0.5771 - accuracy: 0.7975\n",
      "Epoch 9/32\n",
      "973/973 [==============================] - 13s 13ms/step - loss: 0.5689 - accuracy: 0.8005\n",
      "Epoch 10/32\n",
      "973/973 [==============================] - 13s 13ms/step - loss: 0.5636 - accuracy: 0.8025\n",
      "Epoch 11/32\n",
      "973/973 [==============================] - 13s 13ms/step - loss: 0.5591 - accuracy: 0.8046\n",
      "Epoch 12/32\n",
      "973/973 [==============================] - 12s 13ms/step - loss: 0.5540 - accuracy: 0.8054\n",
      "Epoch 13/32\n",
      "973/973 [==============================] - 12s 13ms/step - loss: 0.5450 - accuracy: 0.8070\n",
      "Epoch 14/32\n",
      "973/973 [==============================] - 13s 13ms/step - loss: 0.5439 - accuracy: 0.8079\n",
      "Epoch 15/32\n",
      "973/973 [==============================] - 13s 13ms/step - loss: 0.5393 - accuracy: 0.8106\n",
      "Epoch 16/32\n",
      "973/973 [==============================] - 13s 13ms/step - loss: 0.5322 - accuracy: 0.8114\n",
      "Epoch 17/32\n",
      "973/973 [==============================] - 13s 13ms/step - loss: 0.5328 - accuracy: 0.8107\n",
      "Epoch 18/32\n",
      "973/973 [==============================] - 13s 13ms/step - loss: 0.5259 - accuracy: 0.8138\n",
      "Epoch 19/32\n",
      "973/973 [==============================] - 13s 13ms/step - loss: 0.5226 - accuracy: 0.8157\n",
      "Epoch 20/32\n",
      "973/973 [==============================] - 13s 13ms/step - loss: 0.5182 - accuracy: 0.8162\n",
      "Epoch 21/32\n",
      "973/973 [==============================] - 13s 13ms/step - loss: 0.5139 - accuracy: 0.8185\n",
      "Epoch 22/32\n",
      "973/973 [==============================] - 13s 13ms/step - loss: 0.5101 - accuracy: 0.8191\n",
      "Epoch 23/32\n",
      "973/973 [==============================] - 13s 13ms/step - loss: 0.5065 - accuracy: 0.8197\n",
      "Epoch 24/32\n",
      "973/973 [==============================] - 13s 13ms/step - loss: 0.5036 - accuracy: 0.8223\n",
      "Epoch 25/32\n",
      "973/973 [==============================] - 13s 13ms/step - loss: 0.4985 - accuracy: 0.8226\n",
      "Epoch 26/32\n",
      "973/973 [==============================] - 13s 13ms/step - loss: 0.4948 - accuracy: 0.8233\n",
      "Epoch 27/32\n",
      "973/973 [==============================] - 13s 13ms/step - loss: 0.4939 - accuracy: 0.8243\n",
      "Epoch 28/32\n",
      "973/973 [==============================] - 13s 13ms/step - loss: 0.4882 - accuracy: 0.8258\n",
      "Epoch 29/32\n",
      "973/973 [==============================] - 13s 13ms/step - loss: 0.4824 - accuracy: 0.8278\n",
      "Epoch 30/32\n",
      "973/973 [==============================] - 13s 13ms/step - loss: 0.4823 - accuracy: 0.8277\n",
      "Epoch 31/32\n",
      "973/973 [==============================] - 13s 13ms/step - loss: 0.4794 - accuracy: 0.8306\n",
      "Epoch 32/32\n",
      "973/973 [==============================] - 13s 13ms/step - loss: 0.4726 - accuracy: 0.8315\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.5398 - accuracy: 0.7999\n",
      "Training without 8\n",
      "Epoch 1/32\n",
      "976/976 [==============================] - 13s 13ms/step - loss: 0.7467 - accuracy: 0.7411\n",
      "Epoch 2/32\n",
      "976/976 [==============================] - 13s 13ms/step - loss: 0.6568 - accuracy: 0.7720\n",
      "Epoch 3/32\n",
      "976/976 [==============================] - 13s 13ms/step - loss: 0.6326 - accuracy: 0.7807\n",
      "Epoch 4/32\n",
      "976/976 [==============================] - 13s 13ms/step - loss: 0.6172 - accuracy: 0.7855\n",
      "Epoch 5/32\n",
      "976/976 [==============================] - 13s 13ms/step - loss: 0.6052 - accuracy: 0.7905\n",
      "Epoch 6/32\n",
      "976/976 [==============================] - 13s 13ms/step - loss: 0.5952 - accuracy: 0.7916\n",
      "Epoch 7/32\n",
      "976/976 [==============================] - 13s 13ms/step - loss: 0.5876 - accuracy: 0.7951\n",
      "Epoch 8/32\n",
      "976/976 [==============================] - 13s 13ms/step - loss: 0.5791 - accuracy: 0.7982\n",
      "Epoch 9/32\n",
      "976/976 [==============================] - 13s 13ms/step - loss: 0.5734 - accuracy: 0.7995\n",
      "Epoch 10/32\n",
      "976/976 [==============================] - 13s 13ms/step - loss: 0.5691 - accuracy: 0.8019\n",
      "Epoch 11/32\n",
      "976/976 [==============================] - 13s 13ms/step - loss: 0.5617 - accuracy: 0.8032\n",
      "Epoch 12/32\n",
      "976/976 [==============================] - 13s 13ms/step - loss: 0.5570 - accuracy: 0.8046\n",
      "Epoch 13/32\n",
      "976/976 [==============================] - 13s 13ms/step - loss: 0.5515 - accuracy: 0.8076\n",
      "Epoch 14/32\n",
      "976/976 [==============================] - 13s 13ms/step - loss: 0.5477 - accuracy: 0.8070\n",
      "Epoch 15/32\n",
      "976/976 [==============================] - 13s 13ms/step - loss: 0.5438 - accuracy: 0.8090\n",
      "Epoch 16/32\n",
      "976/976 [==============================] - 13s 13ms/step - loss: 0.5388 - accuracy: 0.8099\n",
      "Epoch 17/32\n",
      "976/976 [==============================] - 13s 13ms/step - loss: 0.5350 - accuracy: 0.8107\n",
      "Epoch 18/32\n",
      "976/976 [==============================] - 13s 13ms/step - loss: 0.5293 - accuracy: 0.8129\n",
      "Epoch 19/32\n",
      "976/976 [==============================] - 13s 13ms/step - loss: 0.5260 - accuracy: 0.8135\n",
      "Epoch 20/32\n",
      "976/976 [==============================] - 13s 13ms/step - loss: 0.5222 - accuracy: 0.8161\n",
      "Epoch 21/32\n",
      "976/976 [==============================] - 13s 13ms/step - loss: 0.5191 - accuracy: 0.8150\n",
      "Epoch 22/32\n",
      "976/976 [==============================] - 13s 13ms/step - loss: 0.5137 - accuracy: 0.8182\n",
      "Epoch 23/32\n",
      "976/976 [==============================] - 13s 13ms/step - loss: 0.5117 - accuracy: 0.8191\n",
      "Epoch 24/32\n",
      "976/976 [==============================] - 13s 13ms/step - loss: 0.5068 - accuracy: 0.8206\n",
      "Epoch 25/32\n",
      "976/976 [==============================] - 13s 13ms/step - loss: 0.5032 - accuracy: 0.8218\n",
      "Epoch 26/32\n",
      "976/976 [==============================] - 13s 13ms/step - loss: 0.4993 - accuracy: 0.8225\n",
      "Epoch 27/32\n",
      "976/976 [==============================] - 13s 13ms/step - loss: 0.4951 - accuracy: 0.8234\n",
      "Epoch 28/32\n",
      "976/976 [==============================] - 13s 13ms/step - loss: 0.4934 - accuracy: 0.8242\n",
      "Epoch 29/32\n",
      "976/976 [==============================] - 13s 13ms/step - loss: 0.4924 - accuracy: 0.8244\n",
      "Epoch 30/32\n",
      "976/976 [==============================] - 13s 13ms/step - loss: 0.4875 - accuracy: 0.8257\n",
      "Epoch 31/32\n",
      "976/976 [==============================] - 13s 13ms/step - loss: 0.4826 - accuracy: 0.8281\n",
      "Epoch 32/32\n",
      "976/976 [==============================] - 13s 13ms/step - loss: 0.4799 - accuracy: 0.8299\n",
      "75/75 [==============================] - 1s 11ms/step - loss: 0.4370 - accuracy: 0.8423\n",
      "Training without 9\n",
      "Epoch 1/32\n",
      "943/943 [==============================] - 13s 13ms/step - loss: 0.7511 - accuracy: 0.7394\n",
      "Epoch 2/32\n",
      "943/943 [==============================] - 12s 13ms/step - loss: 0.6569 - accuracy: 0.7722\n",
      "Epoch 3/32\n",
      "943/943 [==============================] - 12s 13ms/step - loss: 0.6346 - accuracy: 0.7794\n",
      "Epoch 4/32\n",
      "943/943 [==============================] - 12s 13ms/step - loss: 0.6192 - accuracy: 0.7854\n",
      "Epoch 5/32\n",
      "943/943 [==============================] - 12s 13ms/step - loss: 0.6077 - accuracy: 0.7885\n",
      "Epoch 6/32\n",
      "943/943 [==============================] - 12s 12ms/step - loss: 0.5972 - accuracy: 0.7927\n",
      "Epoch 7/32\n",
      "943/943 [==============================] - 12s 12ms/step - loss: 0.5903 - accuracy: 0.7954\n",
      "Epoch 8/32\n",
      "943/943 [==============================] - 12s 12ms/step - loss: 0.5817 - accuracy: 0.7974\n",
      "Epoch 9/32\n",
      "943/943 [==============================] - 12s 12ms/step - loss: 0.5755 - accuracy: 0.7991\n",
      "Epoch 10/32\n",
      "943/943 [==============================] - 12s 13ms/step - loss: 0.5712 - accuracy: 0.8006\n",
      "Epoch 11/32\n",
      "943/943 [==============================] - 12s 12ms/step - loss: 0.5629 - accuracy: 0.8022\n",
      "Epoch 12/32\n",
      "943/943 [==============================] - 12s 12ms/step - loss: 0.5584 - accuracy: 0.8039\n",
      "Epoch 13/32\n",
      "943/943 [==============================] - 11s 12ms/step - loss: 0.5526 - accuracy: 0.8052\n",
      "Epoch 14/32\n",
      "943/943 [==============================] - 12s 13ms/step - loss: 0.5492 - accuracy: 0.8071\n",
      "Epoch 15/32\n",
      "943/943 [==============================] - 12s 13ms/step - loss: 0.5437 - accuracy: 0.8086\n",
      "Epoch 16/32\n",
      "943/943 [==============================] - 12s 13ms/step - loss: 0.5383 - accuracy: 0.8116\n",
      "Epoch 17/32\n",
      "943/943 [==============================] - 12s 13ms/step - loss: 0.5357 - accuracy: 0.8109\n",
      "Epoch 18/32\n",
      "943/943 [==============================] - 12s 13ms/step - loss: 0.5286 - accuracy: 0.8114\n",
      "Epoch 19/32\n",
      "943/943 [==============================] - 12s 13ms/step - loss: 0.5253 - accuracy: 0.8145\n",
      "Epoch 20/32\n",
      "943/943 [==============================] - 12s 13ms/step - loss: 0.5206 - accuracy: 0.8149\n",
      "Epoch 21/32\n",
      "943/943 [==============================] - 12s 13ms/step - loss: 0.5141 - accuracy: 0.8172\n",
      "Epoch 22/32\n",
      "943/943 [==============================] - 12s 13ms/step - loss: 0.5122 - accuracy: 0.8171\n",
      "Epoch 23/32\n",
      "943/943 [==============================] - 12s 12ms/step - loss: 0.5076 - accuracy: 0.8190\n",
      "Epoch 24/32\n",
      "943/943 [==============================] - 11s 12ms/step - loss: 0.5078 - accuracy: 0.8206\n",
      "Epoch 25/32\n",
      "943/943 [==============================] - 12s 13ms/step - loss: 0.5005 - accuracy: 0.8210\n",
      "Epoch 26/32\n",
      "943/943 [==============================] - 12s 13ms/step - loss: 0.4963 - accuracy: 0.8231\n",
      "Epoch 27/32\n",
      "943/943 [==============================] - 12s 13ms/step - loss: 0.4941 - accuracy: 0.8235\n",
      "Epoch 28/32\n",
      "943/943 [==============================] - 12s 13ms/step - loss: 0.4904 - accuracy: 0.8252\n",
      "Epoch 29/32\n",
      "943/943 [==============================] - 12s 13ms/step - loss: 0.4878 - accuracy: 0.8249\n",
      "Epoch 30/32\n",
      "943/943 [==============================] - 12s 13ms/step - loss: 0.4826 - accuracy: 0.8272\n",
      "Epoch 31/32\n",
      "943/943 [==============================] - 11s 12ms/step - loss: 0.4791 - accuracy: 0.8278\n",
      "Epoch 32/32\n",
      "943/943 [==============================] - 11s 12ms/step - loss: 0.4772 - accuracy: 0.8302\n",
      "142/142 [==============================] - 1s 10ms/step - loss: 0.5523 - accuracy: 0.8153\n",
      "Training without 10\n",
      "Epoch 1/32\n",
      "952/952 [==============================] - 11s 12ms/step - loss: 0.7622 - accuracy: 0.7351\n",
      "Epoch 2/32\n",
      "952/952 [==============================] - 11s 11ms/step - loss: 0.6620 - accuracy: 0.7696\n",
      "Epoch 3/32\n",
      "952/952 [==============================] - 12s 13ms/step - loss: 0.6362 - accuracy: 0.7794\n",
      "Epoch 4/32\n",
      "952/952 [==============================] - 11s 11ms/step - loss: 0.6238 - accuracy: 0.7832\n",
      "Epoch 5/32\n",
      "952/952 [==============================] - 11s 11ms/step - loss: 0.6101 - accuracy: 0.7872\n",
      "Epoch 6/32\n",
      "952/952 [==============================] - 11s 11ms/step - loss: 0.6015 - accuracy: 0.7911\n",
      "Epoch 7/32\n",
      "952/952 [==============================] - 11s 11ms/step - loss: 0.5918 - accuracy: 0.7920\n",
      "Epoch 8/32\n",
      "952/952 [==============================] - 11s 11ms/step - loss: 0.5871 - accuracy: 0.7949\n",
      "Epoch 9/32\n",
      "952/952 [==============================] - 11s 11ms/step - loss: 0.5784 - accuracy: 0.7979\n",
      "Epoch 10/32\n",
      "952/952 [==============================] - 11s 12ms/step - loss: 0.5746 - accuracy: 0.8001\n",
      "Epoch 11/32\n",
      "952/952 [==============================] - 12s 13ms/step - loss: 0.5647 - accuracy: 0.8027\n",
      "Epoch 12/32\n",
      "952/952 [==============================] - 11s 12ms/step - loss: 0.5606 - accuracy: 0.8041\n",
      "Epoch 13/32\n",
      "952/952 [==============================] - 12s 12ms/step - loss: 0.5547 - accuracy: 0.8060\n",
      "Epoch 14/32\n",
      "952/952 [==============================] - 12s 13ms/step - loss: 0.5485 - accuracy: 0.8072\n",
      "Epoch 15/32\n",
      "952/952 [==============================] - 12s 13ms/step - loss: 0.5446 - accuracy: 0.8093\n",
      "Epoch 16/32\n",
      "952/952 [==============================] - 12s 13ms/step - loss: 0.5411 - accuracy: 0.8094\n",
      "Epoch 17/32\n",
      "952/952 [==============================] - 12s 13ms/step - loss: 0.5342 - accuracy: 0.8113\n",
      "Epoch 18/32\n",
      "952/952 [==============================] - 12s 13ms/step - loss: 0.5303 - accuracy: 0.8138\n",
      "Epoch 19/32\n",
      "952/952 [==============================] - 12s 13ms/step - loss: 0.5267 - accuracy: 0.8135\n",
      "Epoch 20/32\n",
      "952/952 [==============================] - 12s 13ms/step - loss: 0.5234 - accuracy: 0.8145\n",
      "Epoch 21/32\n",
      "952/952 [==============================] - 12s 13ms/step - loss: 0.5187 - accuracy: 0.8156\n",
      "Epoch 22/32\n",
      "952/952 [==============================] - 12s 13ms/step - loss: 0.5120 - accuracy: 0.8192\n",
      "Epoch 23/32\n",
      "952/952 [==============================] - 12s 13ms/step - loss: 0.5098 - accuracy: 0.8194\n",
      "Epoch 24/32\n",
      "952/952 [==============================] - 12s 13ms/step - loss: 0.5052 - accuracy: 0.8191\n",
      "Epoch 25/32\n",
      "952/952 [==============================] - 12s 13ms/step - loss: 0.5010 - accuracy: 0.8206\n",
      "Epoch 26/32\n",
      "952/952 [==============================] - 12s 13ms/step - loss: 0.4990 - accuracy: 0.8218\n",
      "Epoch 27/32\n",
      "952/952 [==============================] - 12s 13ms/step - loss: 0.4955 - accuracy: 0.8229\n",
      "Epoch 28/32\n",
      "952/952 [==============================] - 12s 13ms/step - loss: 0.4894 - accuracy: 0.8241\n",
      "Epoch 29/32\n",
      "952/952 [==============================] - 12s 13ms/step - loss: 0.4913 - accuracy: 0.8237\n",
      "Epoch 30/32\n",
      "952/952 [==============================] - 11s 11ms/step - loss: 0.4828 - accuracy: 0.8281\n",
      "Epoch 31/32\n",
      "952/952 [==============================] - 11s 11ms/step - loss: 0.4839 - accuracy: 0.8269\n",
      "Epoch 32/32\n",
      "952/952 [==============================] - 11s 11ms/step - loss: 0.4781 - accuracy: 0.8273\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.4574 - accuracy: 0.8484\n",
      "Training without 11\n",
      "Epoch 1/32\n",
      "967/967 [==============================] - 11s 11ms/step - loss: 0.7466 - accuracy: 0.7380\n",
      "Epoch 2/32\n",
      "967/967 [==============================] - 11s 11ms/step - loss: 0.6523 - accuracy: 0.7727\n",
      "Epoch 3/32\n",
      "967/967 [==============================] - 11s 11ms/step - loss: 0.6295 - accuracy: 0.7814\n",
      "Epoch 4/32\n",
      "967/967 [==============================] - 11s 11ms/step - loss: 0.6156 - accuracy: 0.7864\n",
      "Epoch 5/32\n",
      "967/967 [==============================] - 11s 11ms/step - loss: 0.6021 - accuracy: 0.7894\n",
      "Epoch 6/32\n",
      "967/967 [==============================] - 11s 11ms/step - loss: 0.5913 - accuracy: 0.7937\n",
      "Epoch 7/32\n",
      "967/967 [==============================] - 11s 11ms/step - loss: 0.5856 - accuracy: 0.7959\n",
      "Epoch 8/32\n",
      "967/967 [==============================] - 11s 11ms/step - loss: 0.5787 - accuracy: 0.7985\n",
      "Epoch 9/32\n",
      "967/967 [==============================] - 11s 11ms/step - loss: 0.5714 - accuracy: 0.8001\n",
      "Epoch 10/32\n",
      "967/967 [==============================] - 11s 11ms/step - loss: 0.5663 - accuracy: 0.8016\n",
      "Epoch 11/32\n",
      "967/967 [==============================] - 11s 11ms/step - loss: 0.5603 - accuracy: 0.8039\n",
      "Epoch 12/32\n",
      "967/967 [==============================] - 11s 11ms/step - loss: 0.5567 - accuracy: 0.8047\n",
      "Epoch 13/32\n",
      "967/967 [==============================] - 11s 11ms/step - loss: 0.5494 - accuracy: 0.8058\n",
      "Epoch 14/32\n",
      "967/967 [==============================] - 11s 11ms/step - loss: 0.5470 - accuracy: 0.8079\n",
      "Epoch 15/32\n",
      "967/967 [==============================] - 11s 11ms/step - loss: 0.5405 - accuracy: 0.8117\n",
      "Epoch 16/32\n",
      "967/967 [==============================] - 11s 11ms/step - loss: 0.5392 - accuracy: 0.8102\n",
      "Epoch 17/32\n",
      "967/967 [==============================] - 11s 11ms/step - loss: 0.5321 - accuracy: 0.8110\n",
      "Epoch 18/32\n",
      "967/967 [==============================] - 11s 11ms/step - loss: 0.5308 - accuracy: 0.8128\n",
      "Epoch 19/32\n",
      "967/967 [==============================] - 11s 11ms/step - loss: 0.5276 - accuracy: 0.8135\n",
      "Epoch 20/32\n",
      "967/967 [==============================] - 11s 11ms/step - loss: 0.5221 - accuracy: 0.8146\n",
      "Epoch 21/32\n",
      "967/967 [==============================] - 11s 11ms/step - loss: 0.5160 - accuracy: 0.8162\n",
      "Epoch 22/32\n",
      "967/967 [==============================] - 11s 11ms/step - loss: 0.5158 - accuracy: 0.8165\n",
      "Epoch 23/32\n",
      "967/967 [==============================] - 11s 11ms/step - loss: 0.5075 - accuracy: 0.8192\n",
      "Epoch 24/32\n",
      "967/967 [==============================] - 11s 11ms/step - loss: 0.5072 - accuracy: 0.8212\n",
      "Epoch 25/32\n",
      "967/967 [==============================] - 11s 11ms/step - loss: 0.5034 - accuracy: 0.8213\n",
      "Epoch 26/32\n",
      "967/967 [==============================] - 11s 11ms/step - loss: 0.4999 - accuracy: 0.8231\n",
      "Epoch 27/32\n",
      "967/967 [==============================] - 11s 11ms/step - loss: 0.4980 - accuracy: 0.8228\n",
      "Epoch 28/32\n",
      "967/967 [==============================] - 11s 11ms/step - loss: 0.4953 - accuracy: 0.8248\n",
      "Epoch 29/32\n",
      "967/967 [==============================] - 11s 11ms/step - loss: 0.4882 - accuracy: 0.8263\n",
      "Epoch 30/32\n",
      "967/967 [==============================] - 11s 11ms/step - loss: 0.4857 - accuracy: 0.8261\n",
      "Epoch 31/32\n",
      "967/967 [==============================] - 11s 11ms/step - loss: 0.4823 - accuracy: 0.8276\n",
      "Epoch 32/32\n",
      "967/967 [==============================] - 11s 11ms/step - loss: 0.4788 - accuracy: 0.8270\n",
      "92/92 [==============================] - 1s 10ms/step - loss: 0.6180 - accuracy: 0.8266\n",
      "Training without 12\n",
      "Epoch 1/32\n",
      "997/997 [==============================] - 12s 12ms/step - loss: 0.7371 - accuracy: 0.7443\n",
      "Epoch 2/32\n",
      "997/997 [==============================] - 11s 11ms/step - loss: 0.6509 - accuracy: 0.7745\n",
      "Epoch 3/32\n",
      "997/997 [==============================] - 11s 11ms/step - loss: 0.6268 - accuracy: 0.7834\n",
      "Epoch 4/32\n",
      "997/997 [==============================] - 11s 11ms/step - loss: 0.6103 - accuracy: 0.7878\n",
      "Epoch 5/32\n",
      "997/997 [==============================] - 11s 11ms/step - loss: 0.6003 - accuracy: 0.7922\n",
      "Epoch 6/32\n",
      "997/997 [==============================] - 11s 11ms/step - loss: 0.5889 - accuracy: 0.7957\n",
      "Epoch 7/32\n",
      "997/997 [==============================] - 11s 11ms/step - loss: 0.5861 - accuracy: 0.7953\n",
      "Epoch 8/32\n",
      "997/997 [==============================] - 12s 12ms/step - loss: 0.5755 - accuracy: 0.7996\n",
      "Epoch 9/32\n",
      "997/997 [==============================] - 12s 12ms/step - loss: 0.5713 - accuracy: 0.8009\n",
      "Epoch 10/32\n",
      "997/997 [==============================] - 11s 11ms/step - loss: 0.5656 - accuracy: 0.8025\n",
      "Epoch 11/32\n",
      "997/997 [==============================] - 11s 11ms/step - loss: 0.5576 - accuracy: 0.8051\n",
      "Epoch 12/32\n",
      "997/997 [==============================] - 11s 11ms/step - loss: 0.5523 - accuracy: 0.8058\n",
      "Epoch 13/32\n",
      "997/997 [==============================] - 11s 11ms/step - loss: 0.5482 - accuracy: 0.8074\n",
      "Epoch 14/32\n",
      "997/997 [==============================] - 11s 11ms/step - loss: 0.5440 - accuracy: 0.8090\n",
      "Epoch 15/32\n",
      "997/997 [==============================] - 11s 11ms/step - loss: 0.5399 - accuracy: 0.8101\n",
      "Epoch 16/32\n",
      "997/997 [==============================] - 11s 12ms/step - loss: 0.5367 - accuracy: 0.8120\n",
      "Epoch 17/32\n",
      "997/997 [==============================] - 11s 11ms/step - loss: 0.5339 - accuracy: 0.8125\n",
      "Epoch 18/32\n",
      "997/997 [==============================] - 11s 12ms/step - loss: 0.5256 - accuracy: 0.8147\n",
      "Epoch 19/32\n",
      "997/997 [==============================] - 12s 12ms/step - loss: 0.5218 - accuracy: 0.8171\n",
      "Epoch 20/32\n",
      "997/997 [==============================] - 11s 12ms/step - loss: 0.5208 - accuracy: 0.8160\n",
      "Epoch 21/32\n",
      "997/997 [==============================] - 11s 12ms/step - loss: 0.5152 - accuracy: 0.8177\n",
      "Epoch 22/32\n",
      "997/997 [==============================] - 11s 12ms/step - loss: 0.5094 - accuracy: 0.8185\n",
      "Epoch 23/32\n",
      "997/997 [==============================] - 11s 11ms/step - loss: 0.5084 - accuracy: 0.8211\n",
      "Epoch 24/32\n",
      "997/997 [==============================] - 12s 12ms/step - loss: 0.5028 - accuracy: 0.8216\n",
      "Epoch 25/32\n",
      "997/997 [==============================] - 11s 12ms/step - loss: 0.5014 - accuracy: 0.8211\n",
      "Epoch 26/32\n",
      "997/997 [==============================] - 12s 12ms/step - loss: 0.4938 - accuracy: 0.8232\n",
      "Epoch 27/32\n",
      "997/997 [==============================] - 11s 12ms/step - loss: 0.4950 - accuracy: 0.8237\n",
      "Epoch 28/32\n",
      "997/997 [==============================] - 11s 11ms/step - loss: 0.4949 - accuracy: 0.8243\n",
      "Epoch 29/32\n",
      "997/997 [==============================] - 11s 11ms/step - loss: 0.4861 - accuracy: 0.8270\n",
      "Epoch 30/32\n",
      "997/997 [==============================] - 12s 12ms/step - loss: 0.4845 - accuracy: 0.8265\n",
      "Epoch 31/32\n",
      "997/997 [==============================] - 12s 12ms/step - loss: 0.4806 - accuracy: 0.8266\n",
      "Epoch 32/32\n",
      "997/997 [==============================] - 12s 12ms/step - loss: 0.4734 - accuracy: 0.8294\n",
      "34/34 [==============================] - 0s 11ms/step - loss: 0.5894 - accuracy: 0.7924\n"
     ]
    }
   ],
   "source": [
    "for test_subject in subject_to_indices.keys():\n",
    "    # Load the data\n",
    "    print(f\"Training without {test_subject}\")\n",
    "    results = []\n",
    "    accuracy = []\n",
    "    loss = []\n",
    "    model = build_model(input_shape=(20,6))\n",
    "    train_data, train_labels, test_data, test_labels = load_data(test_subject, subject_to_indices)\n",
    "    history = model.fit(train_data, train_labels, epochs=32, batch_size=64)\n",
    "    results.append(model.evaluate(test_data, test_labels))\n",
    "    accuracy.append(history.history['accuracy'])\n",
    "    loss.append(history.history['loss'])\n",
    "    model.save(f\"../models/full_loso/majority_label/processed/mean_std_3/model_{test_subject}.keras\")\n",
    "    \n",
    "    training_info_path = \"../models/full_loso/majority_label/processed/mean_std_3/training_info/\" \n",
    "    os.makedirs(training_info_path, exist_ok=True)\n",
    "    save_data(results, training_info_path, f\"results_{test_subject}\")\n",
    "    save_data(accuracy, training_info_path, f\"accuracy_{test_subject}\")\n",
    "    save_data(loss, training_info_path, f\"loss_{test_subject}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-03T21:51:59.522824Z",
     "start_time": "2024-02-03T20:38:19.371389Z"
    }
   },
   "id": "b82674018ad09163"
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation: 79.56640323003134%\n",
      "Accuracy: 80.94775970093906%\n",
      "Loss: 63.53173702955246%\n"
     ]
    }
   ],
   "source": [
    "# history.history['accuracy']\n",
    "tot_acc = []\n",
    "tot_res = []\n",
    "tot_loss = []\n",
    "info_path = \"../models/full_loso/majority_label/processed/mean_std_3/training_info\"\n",
    "for i in range(1,13):\n",
    "    with open(f\"{info_path}/accuracy_{i}.pkl\", \"rb\") as a:\n",
    "        tot_acc.append(pickle.load(a))\n",
    "    with open(f\"{info_path}/results_{i}.pkl\", \"rb\") as r:\n",
    "        tot_res.append(pickle.load(r))\n",
    "    with open(f\"{info_path}/loss_{i}.pkl\", \"rb\") as l:\n",
    "        tot_loss.append(pickle.load(l))\n",
    "\n",
    "tot_res = np.concatenate(tot_res)\n",
    "tot_acc = np.concatenate(tot_acc)\n",
    "tot_loss = np.concatenate(tot_loss)\n",
    "\n",
    "print(f\"Evaluation: {np.mean(tot_res[:,1])*100}%\")\n",
    "print(f\"Accuracy: {np.mean(tot_acc)*100}%\")\n",
    "print(f\"Loss: {np.mean(tot_res[:,0])*100}%\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-04T01:04:35.529590Z",
     "start_time": "2024-02-04T01:04:35.519889Z"
    }
   },
   "id": "dec99c1826009149"
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[0.75614339, 0.65435392, 0.63145953, 0.61665827, 0.60239607,\n        0.59254134, 0.58622319, 0.5772047 , 0.57176536, 0.56493288,\n        0.55884326, 0.55213171, 0.54851186, 0.5422467 , 0.53837776,\n        0.53398985, 0.53016746, 0.52553058, 0.52117985, 0.51914328,\n        0.51350856, 0.50858009, 0.50235802, 0.5010227 , 0.49814254,\n        0.49248004, 0.48707789, 0.48182166, 0.47663063, 0.47622734,\n        0.47290981, 0.46919096],\n       [0.76381189, 0.66896796, 0.64357871, 0.62668639, 0.61258781,\n        0.60255265, 0.59373611, 0.58503115, 0.57967776, 0.57218271,\n        0.56759501, 0.56094217, 0.55642712, 0.55350399, 0.54746884,\n        0.54524457, 0.53760231, 0.53334343, 0.53070319, 0.52803856,\n        0.52146858, 0.519777  , 0.51445985, 0.51265746, 0.5074895 ,\n        0.50312352, 0.50126779, 0.49547672, 0.49367639, 0.49053273,\n        0.48666561, 0.48179689],\n       [0.7372759 , 0.63981593, 0.61673158, 0.60458446, 0.59282297,\n        0.5814684 , 0.57517779, 0.56678975, 0.56338835, 0.55602074,\n        0.54588801, 0.54236621, 0.53643066, 0.53490943, 0.5294143 ,\n        0.52329177, 0.51985979, 0.51414979, 0.50904685, 0.50685376,\n        0.50054741, 0.49873906, 0.49537691, 0.48911783, 0.4856756 ,\n        0.4816269 , 0.4748852 , 0.47192326, 0.47099814, 0.46673229,\n        0.4621872 , 0.45665932],\n       [0.69388306, 0.58897394, 0.5646162 , 0.54832643, 0.53809124,\n        0.52957034, 0.51881176, 0.51156843, 0.50372201, 0.49771801,\n        0.49311724, 0.48691976, 0.48333618, 0.47602141, 0.47212178,\n        0.46728691, 0.46270797, 0.45744446, 0.45733058, 0.45234525,\n        0.44714427, 0.4439266 , 0.4399462 , 0.43416339, 0.43067479,\n        0.42688921, 0.42328435, 0.42157149, 0.41670862, 0.41591933,\n        0.41069353, 0.40895537],\n       [0.74853551, 0.65664321, 0.63083887, 0.61304396, 0.60168976,\n        0.59375012, 0.58413446, 0.57852072, 0.57109374, 0.56475604,\n        0.55915934, 0.55448681, 0.54750979, 0.542054  , 0.53900242,\n        0.53230649, 0.53038675, 0.52547169, 0.52060741, 0.51316363,\n        0.51138848, 0.50778419, 0.50375885, 0.50096154, 0.49808931,\n        0.49229598, 0.48912147, 0.48612556, 0.48518595, 0.47805819,\n        0.47516972, 0.47047439],\n       [0.75313783, 0.65686208, 0.63125312, 0.61657482, 0.60433137,\n        0.59397864, 0.58694857, 0.57927966, 0.57365209, 0.56505716,\n        0.56215847, 0.55563235, 0.55147171, 0.54650277, 0.54129344,\n        0.53661489, 0.53312582, 0.53073901, 0.52424353, 0.52163976,\n        0.51527172, 0.51262373, 0.50810504, 0.50479233, 0.50311095,\n        0.49803892, 0.49238971, 0.49097896, 0.48987874, 0.48507851,\n        0.48131168, 0.47967377],\n       [0.74883097, 0.65603286, 0.63058013, 0.61428976, 0.60245532,\n        0.59110177, 0.58290273, 0.57708591, 0.56886458, 0.56359386,\n        0.55914599, 0.55400097, 0.54497457, 0.54386508, 0.53930044,\n        0.53223616, 0.53284311, 0.52588832, 0.5225994 , 0.518215  ,\n        0.51389122, 0.51010197, 0.5064705 , 0.50358778, 0.49846596,\n        0.49481982, 0.4938899 , 0.48818094, 0.4824456 , 0.48230532,\n        0.47938302, 0.472626  ],\n       [0.7467382 , 0.65677953, 0.63261217, 0.61715627, 0.6051966 ,\n        0.59519005, 0.58761072, 0.57908672, 0.57336432, 0.56908405,\n        0.56166953, 0.55698287, 0.55153465, 0.54767466, 0.54376149,\n        0.53878987, 0.53501427, 0.5293265 , 0.52597928, 0.52224153,\n        0.51914668, 0.51366806, 0.51173264, 0.5068475 , 0.50320399,\n        0.49934012, 0.49509531, 0.49341068, 0.49239045, 0.48747844,\n        0.48256585, 0.4799307 ],\n       [0.7511149 , 0.65690118, 0.63455033, 0.61922336, 0.60766512,\n        0.59721392, 0.5903002 , 0.58165228, 0.57547176, 0.57121176,\n        0.56285924, 0.55843836, 0.55255145, 0.54916126, 0.54367864,\n        0.53834999, 0.53574729, 0.52861851, 0.52531558, 0.52058274,\n        0.51408565, 0.51218188, 0.50762486, 0.50779361, 0.50047362,\n        0.49628147, 0.49405706, 0.49036783, 0.48778427, 0.48259851,\n        0.47910124, 0.47718832],\n       [0.7621665 , 0.66201389, 0.63615447, 0.6238237 , 0.61014956,\n        0.60154259, 0.59181035, 0.58712137, 0.57842714, 0.57461524,\n        0.56465399, 0.56060791, 0.55469531, 0.54851294, 0.54456323,\n        0.5411154 , 0.53418118, 0.53033632, 0.52674937, 0.52344459,\n        0.5187065 , 0.51200235, 0.50980568, 0.50518453, 0.50102788,\n        0.49901792, 0.49550056, 0.48944756, 0.49128568, 0.48278716,\n        0.48387492, 0.47810322],\n       [0.74662507, 0.65225828, 0.62945825, 0.61556458, 0.60212868,\n        0.59133303, 0.58556426, 0.57866931, 0.57142752, 0.5662933 ,\n        0.56033397, 0.556705  , 0.54937571, 0.54700255, 0.54051614,\n        0.53918475, 0.53211808, 0.53079718, 0.52762097, 0.52212495,\n        0.51600099, 0.51584834, 0.50750005, 0.50721931, 0.50335336,\n        0.49986029, 0.49804688, 0.49527022, 0.48818484, 0.48567265,\n        0.48230729, 0.47883284],\n       [0.73713648, 0.65094995, 0.62678653, 0.6103248 , 0.6003384 ,\n        0.58890629, 0.58605546, 0.57549971, 0.57127452, 0.56558031,\n        0.55764335, 0.55228013, 0.54823989, 0.54399723, 0.53990448,\n        0.53665394, 0.53394985, 0.52555096, 0.52179837, 0.5208233 ,\n        0.5151732 , 0.50939637, 0.50842994, 0.50277853, 0.5013932 ,\n        0.49384937, 0.4950473 , 0.4949021 , 0.48613364, 0.48449799,\n        0.480602  , 0.47335738]])"
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tot_loss"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-04T01:05:04.948828Z",
     "start_time": "2024-02-04T01:05:04.939175Z"
    }
   },
   "id": "8cf413fd000cc239"
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [
    {
     "data": {
      "text/plain": "0.4688990960518519"
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(tot_loss[:,31])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-04T01:05:39.108960Z",
     "start_time": "2024-02-04T01:05:39.098635Z"
    }
   },
   "id": "29d1a933abf2fb29"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(f\"Result: {np.mean(tot_res_copy[:,0])*100}%\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4a824ac5d49a21dc"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "metrics_values = evaluation_results[1, :]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "61ead0d3ea3cc93a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tot_res_copy = tot_res"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9216df854f478b68"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tot_res_copy = np.concatenate(tot_res_copy)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d51ccabd0823fc2d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tot_res_copy"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "92ef0c794207bc1b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tot_loss[:,31]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8ba9c17b9b50b871"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# epochs = range(len(acc))  # Number of epochs"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e9c598c094e26a58"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "np.mean(accuracy[0][:])\n",
    "avg_accuracy = [np.mean(sublist) for sublist in accuracy]\n",
    "avg_accuracy"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "aaa1c03bb8f28e2e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "np.mean(avg_accuracy)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ebf9824f9689a3f1"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "np.mean(loss)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7e8b31f6634ab50c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# # Plotting training and validation accuracy\n",
    "# plt.figure(figsize=(12, 4))\n",
    "# plt.subplot(1, 2, 1)\n",
    "# plt.plot(epochs, acc, label='Training Accuracy')\n",
    "# # plt.plot(epochs, val_acc, label='Validation Accuracy')\n",
    "# plt.title('Training Accuracy')\n",
    "# plt.legend()\n",
    "# \n",
    "# # Plotting training and validation loss\n",
    "# plt.subplot(1, 2, 2)\n",
    "# plt.plot(epochs, loss, label='Training Loss')\n",
    "# # plt.plot(epochs, val_loss, label='Validation Loss')\n",
    "# plt.title('Training Loss')\n",
    "# plt.legend()\n",
    "# \n",
    "# plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "313650f827ed77f3"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# def build_lstm():\n",
    "#     lstm_model = Sequential()\n",
    "#     lstm_model.add(TimeDistributed(cnn_model, input_shape=(35, input_shape[0], input_shape[1])))  # Assuming input_shape is (20, 6)\n",
    "#     lstm_model.add(LSTM(64, activation='tanh', recurrent_activation='hard_sigmoid', return_sequences=True))\n",
    "#     lstm_model.add(LSTM(64, activation='tanh', recurrent_activation='hard_sigmoid'))\n",
    "#     lstm_model.add(Dropout(0.5))\n",
    "#     lstm_model.add(Dense(1, activation='sigmoid'))  # Binary classification\n",
    "# \n",
    "#     lstm_model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "#     return lstm_model\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2383932c09f077e2"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
