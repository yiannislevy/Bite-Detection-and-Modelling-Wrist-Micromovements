{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import keras.models\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout\n",
    "from keras.optimizers import Adam\n",
    "import tensorflow\n",
    "from keras.optimizers.legacy import Adam as LegacyAdam\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "import pickle as pkl\n",
    "from src.utils.data_transform import *\n",
    "from src.utils.data_io import load_data\n",
    "import pandas as pd\n",
    "import os \n",
    "import pickle \n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "from src.utils.data_io import save_data\n",
    "from src.analysis.viz_training import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def build_model(input_shape):\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(filters=64, kernel_size=10, activation='relu', input_shape=input_shape, padding='same'))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(Conv1D(filters=128, kernel_size=10, activation='relu', padding='same'))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(5, activation='softmax'))  # Assuming 5 classes for the output layer\n",
    "    # optimizer = Adam(learning_rate=1e-3)\n",
    "    optimizer = LegacyAdam(learning_rate=1e-3)\n",
    "    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=[\"accuracy\"])\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bd23a6c2f6f0f64b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = build_model((20,6))\n",
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ed198dd192e661bb"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "with open(\"../../data/dataset-info-json/subject_to_indices.json\", \"r\") as f:\n",
    "    subject_to_indices = json.load(f)\n",
    "\n",
    "subject_to_indices = {int(k): v for k, v in subject_to_indices.items()}\n",
    "\n",
    "path_to_data = \"../../data/ProcessedSubjects/MajorityLabel/sessions/grav_n_med/full_std_3\"\n",
    "path_to_save = \"../../models/cnn/1000\"\n",
    "training_info_path = \"../../models/cnn/1000/training_info\" \n",
    "os.makedirs(training_info_path, exist_ok=True)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "22ff591737b11994"
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Train LOSO**"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bb0c21085bcf524"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "d7e54bc12c8c879d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for test_subject in subject_to_indices.keys():\n",
    "    # Load the data\n",
    "    print(f\"Training without {test_subject}\")\n",
    "    results = []\n",
    "    accuracy = []\n",
    "    loss = []\n",
    "    model = build_model(input_shape=(20,6))\n",
    "    train_data, train_labels, test_data, test_labels = load_data(test_subject, subject_to_indices, path_to_data)\n",
    "    history = model.fit(train_data, train_labels, epochs=32, batch_size=64)\n",
    "    results.append(model.evaluate(test_data, test_labels))\n",
    "    accuracy.append(history.history['accuracy'])\n",
    "    loss.append(history.history['loss'])\n",
    "    model.save(f\"{path_to_save}/model_{test_subject}.keras\")\n",
    "    \n",
    "    save_data(results, training_info_path, f\"results_{test_subject}\")\n",
    "    save_data(accuracy, training_info_path, f\"accuracy_{test_subject}\")\n",
    "    save_data(loss, training_info_path, f\"loss_{test_subject}\")\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b82674018ad09163"
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Load and display results**"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "77ff2b7c19ec9bd"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tot_acc = []\n",
    "tot_res = []\n",
    "tot_loss = []\n",
    "info_path = \"../models/full_loso/majority_label/processed/mean_std_3/training_info\"\n",
    "for i in range(1,13):\n",
    "    with open(f\"{info_path}/accuracy_{i}.pkl\", \"rb\") as a:\n",
    "        tot_acc.append(pickle.load(a))\n",
    "    with open(f\"{info_path}/results_{i}.pkl\", \"rb\") as r:\n",
    "        tot_res.append(pickle.load(r))\n",
    "    with open(f\"{info_path}/loss_{i}.pkl\", \"rb\") as l:\n",
    "        tot_loss.append(pickle.load(l))\n",
    "\n",
    "tot_res = np.concatenate(tot_res)\n",
    "tot_acc = np.concatenate(tot_acc)\n",
    "tot_loss = np.concatenate(tot_loss)\n",
    "\n",
    "print(f\"Evaluation: {np.mean(tot_res[:,1])*100}%\")\n",
    "print(f\"Accuracy: {np.mean(tot_acc)*100}%\")\n",
    "print(f\"Loss: {np.mean(tot_res[:,0])*100}%\")\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dec99c1826009149"
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Train FULL**"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "af397d9a8d2a5589"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "import datetime\n",
    "import os\n",
    "\n",
    "path = \"../../models/cnn/test_1000/\"\n",
    "log_dir = os.path.join(path, \"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "checkpoint_dir = os.path.join(path, \"checkpoints\")\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "checkpoint_path = os.path.join(checkpoint_dir, \"cp-{epoch:04d}.ckpt\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a79f54b2fd287530"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = build_model(input_shape=(20,6))\n",
    "train_data, train_labels, test_data, test_labels = load_data(1, subject_to_indices, path_to_data)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b1905ac8dfe173da"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "all_data = np.concatenate((train_data, test_data), axis=0)\n",
    "all_labels = np.concatenate((train_labels, test_labels), axis=0)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f441c91c5b003fd4"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tensorboard_callback = TensorBoard(\n",
    "    log_dir=log_dir,\n",
    "    histogram_freq=1,  # Record activation histograms every epoch\n",
    "    write_graph=True,  # Visualize the graph\n",
    "    write_images=True,  # Store images of the weights\n",
    "    update_freq='epoch',\n",
    "    profile_batch=2,  # Profiling the second batch to look at performance bottlenecks\n",
    "    embeddings_freq=1,  # Visualize embeddings\n",
    ")\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4307ad0d1fdbe15"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model_checkpoint_callback = ModelCheckpoint(\n",
    "    filepath=checkpoint_path,\n",
    "    save_weights_only=True,\n",
    "    verbose=1,\n",
    "    save_freq='epoch',\n",
    "    monitor='accuracy',  # Or another metric like 'val_accuracy'\n",
    "    save_best_only=True,\n",
    "    mode='max'  # Use 'max' for metrics where higher is better, like accuracy\n",
    ")\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "82e7b16a4b10d700"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "epochs = 1000\n",
    "history = model.fit(\n",
    "    train_data,\n",
    "    train_labels,\n",
    "    epochs=epochs,\n",
    "    batch_size=64,\n",
    "    callbacks=[tensorboard_callback, model_checkpoint_callback]\n",
    ")\n",
    "\n",
    "model.save(f\"{path}/model_{epochs}_test.keras\")\n",
    "\n",
    "acc = history.history[\"accuracy\"]\n",
    "loss = history.history[\"loss\"]\n",
    "res = model.evaluate(test_data, test_labels)\n",
    "\n",
    "save_data(acc, f\"{path}/training_info\", f\"accuracy_{epochs}_1\")\n",
    "save_data(loss, f\"{path}/training_info\", f\"loss_{epochs}_1\")\n",
    "save_data(res, f\"{path}/training_info\", f\"results_{epochs}_1\")\n",
    "\n",
    "plot_metric(acc,\"Accuracy\", f\"../../models/cnn/test_{epochs}/figs/training_acc.svg\")\n",
    "plot_metric(loss,\"Loss\", f\"../../models/cnn/test_{epochs}/figs/training_loss.svg\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6001a2d1cd75e41e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Load model from checkpoint and evaluate**"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "56e2758cce6413f1"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "checkpoint_dir = \"../../models/cnn/test_1000/checkpoints/\"\n",
    "ckpt_model = build_model((20,6))\n",
    "results = evaluate_checkpoints(checkpoint_dir, test_data, test_labels, ckpt_model)\n",
    "print(f\"Best checkpoint: {results['best_ckpt']}\")\n",
    "print(f\"Best accuracy: {results['best_accuracy']:.4f}\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b1401e652887ddf2"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Extract the accuracy of each checkpoint and store them in a list\n",
    "accuracies = [result['accuracy'] for result in results['all_results']]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "827f37c6a455ec12"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "plot_metric(accuracies, \"Easy Accuracy from ckpts - Subject_1\", \"../../models/cnn/test_1000/figs/easy_acc_from_ckpts.svg\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8807dda8e3a3383d"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
