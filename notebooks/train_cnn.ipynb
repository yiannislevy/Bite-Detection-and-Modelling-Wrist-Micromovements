{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "from keras.optimizers.legacy import Adam as LegacyAdam\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "import pickle as pkl\n",
    "from src.utils.data_transform import *\n",
    "import pandas as pd\n",
    "import os \n",
    "import pickle \n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def load_data(test_subject, subject_to_indices):\n",
    "    training_data, testing_data, validation_data = [], [], []\n",
    "    training_labels, testing_labels, validation_labels = [], [], []\n",
    "\n",
    "    # Load training data (all subjects except the test and validation subjects)\n",
    "    for subject in subject_to_indices.keys():\n",
    "        if subject != test_subject :\n",
    "            # and subject != validation_subject:\n",
    "            subject_data, subject_labels = load_subject_data(f\"../data/ProcessedSubjects/MajorityLabel(95%)/subject_{subject}/data.pkl\")\n",
    "            training_data.append(subject_data)\n",
    "            training_labels.append(subject_labels)\n",
    "\n",
    "    # Load testing data (only the test subject)\n",
    "    test_data, test_labels = load_subject_data(f\"../data/ProcessedSubjects/subject_{test_subject}/data.pkl\")\n",
    "    testing_data.append(test_data)\n",
    "    testing_labels.append(test_labels)\n",
    "\n",
    "    # # Load validation data (only the validation subject)\n",
    "    # val_data, val_labels = load_subject_data(f\"../data/ProcessedSubjects/subject_{validation_subject}/data.pkl\")\n",
    "    # validation_data.append(val_data)\n",
    "    # validation_labels.append(val_labels)\n",
    "\n",
    "    # Combine all training, testing, and validation data and labels\n",
    "    training_data = np.concatenate(training_data, axis=0)\n",
    "    training_labels = np.concatenate(training_labels, axis=0)\n",
    "    testing_data = np.concatenate(testing_data, axis=0)\n",
    "    testing_labels = np.concatenate(testing_labels, axis=0)\n",
    "    # validation_data = np.concatenate(validation_data, axis=0)\n",
    "    # validation_labels = np.concatenate(validation_labels, axis=0)\n",
    "\n",
    "    return training_data, training_labels, testing_data, testing_labels\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e6db3b735e7aab70"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def load_subject_data(path):\n",
    "    data = pd.read_pickle(path)\n",
    "    signal_data = np.array([item[0] for item in data])\n",
    "    label_data = np.array([item[1] for item in data])\n",
    "    return signal_data, label_data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6bf9be48179ef32"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def build_model(input_shape):\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(filters=64, kernel_size=10, activation='relu', input_shape=input_shape, padding='same'))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(Conv1D(filters=128, kernel_size=10, activation='relu', padding='same'))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(5, activation='softmax'))  # Assuming 5 classes for the output layer\n",
    "    # optimizer = Adam(learning_rate=1e-3)\n",
    "    optimizer = LegacyAdam(learning_rate=1e-3)\n",
    "    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=[\"accuracy\"])\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bd23a6c2f6f0f64b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "with open(\"../data/processed.nosync/subject_to_indices.json\", \"r\") as f:\n",
    "    subject_to_indices = json.load(f)\n",
    "\n",
    "subject_to_indices = {int(k): v for k, v in subject_to_indices.items()}"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "22ff591737b11994"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "results = []\n",
    "accuracy = []\n",
    "loss = []"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8f1ed92ed4c03da1"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for test_subject in subject_to_indices.keys():\n",
    "    # Load the data\n",
    "    print(f\"Training without {test_subject}\")\n",
    "    model = build_model(input_shape=(20,6))\n",
    "    train_data, train_labels, test_data, test_labels = load_data(test_subject, subject_to_indices)\n",
    "    history = model.fit(train_data, train_labels, epochs=32, batch_size=64)\n",
    "    results.append(model.evaluate(test_data, test_labels))\n",
    "    accuracy.append(history.history['accuracy'])\n",
    "    loss.append(history.history['loss'])\n",
    "    model.save(f\"../models/full_loso/model_{test_subject}.keras\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b82674018ad09163"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "history.history['accuracy']"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dec99c1826009149"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# epochs = range(len(acc))  # Number of epochs"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e9c598c094e26a58"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "np.mean(accuracy[0][:])\n",
    "avg_accuracy = [np.mean(sublist) for sublist in accuracy]\n",
    "avg_accuracy"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "aaa1c03bb8f28e2e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "np.mean(avg_accuracy)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ebf9824f9689a3f1"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "np.mean(loss)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7e8b31f6634ab50c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# # Plotting training and validation accuracy\n",
    "# plt.figure(figsize=(12, 4))\n",
    "# plt.subplot(1, 2, 1)\n",
    "# plt.plot(epochs, acc, label='Training Accuracy')\n",
    "# # plt.plot(epochs, val_acc, label='Validation Accuracy')\n",
    "# plt.title('Training Accuracy')\n",
    "# plt.legend()\n",
    "# \n",
    "# # Plotting training and validation loss\n",
    "# plt.subplot(1, 2, 2)\n",
    "# plt.plot(epochs, loss, label='Training Loss')\n",
    "# # plt.plot(epochs, val_loss, label='Validation Loss')\n",
    "# plt.title('Training Loss')\n",
    "# plt.legend()\n",
    "# \n",
    "# plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "313650f827ed77f3"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# def build_lstm():\n",
    "#     lstm_model = Sequential()\n",
    "#     lstm_model.add(TimeDistributed(cnn_model, input_shape=(35, input_shape[0], input_shape[1])))  # Assuming input_shape is (20, 6)\n",
    "#     lstm_model.add(LSTM(64, activation='tanh', recurrent_activation='hard_sigmoid', return_sequences=True))\n",
    "#     lstm_model.add(LSTM(64, activation='tanh', recurrent_activation='hard_sigmoid'))\n",
    "#     lstm_model.add(Dropout(0.5))\n",
    "#     lstm_model.add(Dense(1, activation='sigmoid'))  # Binary classification\n",
    "# \n",
    "#     lstm_model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "#     return lstm_model\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2383932c09f077e2"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
